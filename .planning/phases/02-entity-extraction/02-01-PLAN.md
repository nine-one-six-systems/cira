---
phase: 02-entity-extraction
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/tests/test_extraction_integration.py
  - backend/tests/fixtures/extraction_fixtures.py
autonomous: true

must_haves:
  truths:
    - "Entity extraction pipeline processes crawled pages end-to-end"
    - "NER extracts PERSON, ORG, GPE, PRODUCT entities with confidence scores"
    - "Structured extraction finds emails, phones, addresses, social handles"
    - "Deduplication merges identical entities across multiple pages"
    - "Role detection identifies CEO, Founder, CTO, VP roles from context"
  artifacts:
    - path: "backend/tests/test_extraction_integration.py"
      provides: "Integration tests for full extraction pipeline"
      min_lines: 200
    - path: "backend/tests/fixtures/extraction_fixtures.py"
      provides: "Shared fixtures for extraction testing"
      min_lines: 80
  key_links:
    - from: "EntityExtractor"
      to: "NLPPipeline"
      via: "nlp.process_text()"
      pattern: "nlp\\.process_text"
    - from: "EntityExtractor"
      to: "StructuredDataExtractor"
      via: "extract_all() for emails/phones"
      pattern: "extract_emails|extract_phones"
    - from: "EntityExtractor"
      to: "EntityDeduplicator"
      via: "deduplicate_entities()"
      pattern: "deduplicate"
---

<objective>
Create integration tests for the entity extraction pipeline that verify all components work together correctly.

Purpose: Validate that existing NER and structured extraction implementation meets Phase 2 requirements when components are integrated, catching wiring issues that unit tests miss.

Output: Integration test file with realistic company page content exercising full extraction flow.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-entity-extraction/02-RESEARCH.md
@backend/app/extractors/nlp_pipeline.py
@backend/app/extractors/entity_extractor.py
@backend/app/extractors/structured_extractor.py
@backend/app/extractors/deduplicator.py
@backend/tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create extraction integration test fixtures</name>
  <files>backend/tests/fixtures/extraction_fixtures.py</files>
  <action>
Create shared fixtures for extraction integration testing at `backend/tests/fixtures/extraction_fixtures.py`:

1. If `backend/tests/fixtures/__init__.py` doesn't exist, create it (empty file)

2. Create `backend/tests/fixtures/extraction_fixtures.py` with:
   - `ABOUT_PAGE_TEXT`: Realistic about page content (300+ words) containing:
     - Company name and founding date
     - Founder/CEO names with roles ("John Smith, CEO and Co-founder")
     - Office location ("San Francisco, California")
     - Partner/investor organization mentions ("backed by Sequoia Capital")
     - Products/services mentioned
     - Contact email and phone number

   - `TEAM_PAGE_TEXT`: Team page content (250+ words) containing:
     - Multiple person names with different roles (CEO, CTO, VP Engineering, etc.)
     - Person names appearing multiple times (for deduplication testing)
     - Mix of full names and initials ("J. Smith" and "John Smith")
     - Department affiliations

   - `CONTACT_PAGE_TEXT`: Contact page content containing:
     - Multiple email addresses (info@, support@, sales@)
     - Phone numbers in different formats ((555) 123-4567, 555.123.4567)
     - Physical address with street, city, state, ZIP
     - Social media links (LinkedIn, Twitter, Facebook)

   - `CAREERS_PAGE_TEXT`: Careers page content containing:
     - Tech stack mentions (Python, React, PostgreSQL, AWS, etc.)
     - Job titles with department info

   - `create_company_with_pages(db)`: Factory function that:
     - Creates a Company record
     - Creates Page records for about, team, contact, careers pages
     - Returns company object with page IDs

   - `DUPLICATE_ENTITY_TEXT`: Text with intentional duplicates for dedup testing:
     - Same person mentioned 3+ times with name variations
     - Same email mentioned twice
     - Same organization with "Inc." and without

Use pytest fixture patterns that can be imported into test files.
  </action>
  <verify>
```bash
cd /Users/stephenhollifield/Cira && python3 -c "from backend.tests.fixtures.extraction_fixtures import ABOUT_PAGE_TEXT, TEAM_PAGE_TEXT, create_company_with_pages; print('Fixtures import OK')"
```
  </verify>
  <done>Fixture module exists with realistic company page content for extraction testing.</done>
</task>

<task type="auto">
  <name>Task 2: Create extraction pipeline integration tests</name>
  <files>backend/tests/test_extraction_integration.py</files>
  <action>
Create integration tests that verify the full extraction pipeline in `backend/tests/test_extraction_integration.py`:

1. **Test class: TestNERExtraction**
   Tests NER-01 through NER-05:

   - `test_extracts_person_entities_with_roles` (NER-01, NER-05):
     - Use TEAM_PAGE_TEXT fixture
     - Extract entities via EntityExtractor
     - Assert PERSON entities found
     - Assert at least one person has role in extra_data (CEO, Founder, etc.)
     - Verify confidence scores are between 0 and 1

   - `test_extracts_organization_entities_with_relationships` (NER-02):
     - Use ABOUT_PAGE_TEXT fixture
     - Assert ORG entities found
     - Assert relationship detection works (partner, investor, client)

   - `test_extracts_location_entities` (NER-03):
     - Use ABOUT_PAGE_TEXT fixture
     - Assert GPE/location entities found
     - Verify city and state extracted

   - `test_extracts_product_entities` (NER-04):
     - Use text mentioning specific products
     - Assert PRODUCT entities found

2. **Test class: TestStructuredDataExtraction**
   Tests NER-06:

   - `test_extracts_emails_with_validation`:
     - Use CONTACT_PAGE_TEXT fixture
     - Assert emails extracted
     - Assert invalid domains (example.com) rejected
     - Verify normalized format

   - `test_extracts_phones_with_normalization`:
     - Use CONTACT_PAGE_TEXT with multiple phone formats
     - Assert phones extracted
     - Verify E.164 normalization (+15551234567)

   - `test_extracts_addresses`:
     - Use CONTACT_PAGE_TEXT
     - Assert address entity found with street, city, state

   - `test_extracts_social_handles`:
     - Use CONTACT_PAGE_TEXT with social URLs
     - Assert social_handle entities found
     - Verify platform metadata (twitter, linkedin, etc.)

3. **Test class: TestDeduplication**
   Tests NER-07:

   - `test_deduplicates_identical_entities_across_pages`:
     - Create company with multiple pages mentioning same entity
     - Run extraction
     - Assert duplicates merged
     - Assert source_urls contains all sources

   - `test_deduplicates_person_name_variations`:
     - Use text with "John Smith" and "J. Smith"
     - Assert merged into single entity
     - Assert longer name used as canonical

   - `test_deduplicates_org_name_variations`:
     - Use text with "Google" and "Google Inc."
     - Assert merged into single entity

   - `test_confidence_boosted_by_multiple_mentions`:
     - Entity mentioned 5+ times
     - Assert final confidence > base confidence

4. **Test class: TestFullPipeline**

   - `test_extract_and_save_for_company` (app fixture required):
     - Create company with pages via create_company_with_pages()
     - Call entity_extractor.save_entities_for_company()
     - Query Entity table
     - Assert entities saved with correct types
     - Assert entities have source_url, context_snippet

   - `test_extraction_handles_empty_pages`:
     - Create page with empty extracted_text
     - Assert extraction completes without error
     - Assert 0 entities extracted

   - `test_extraction_handles_non_english_gracefully`:
     - Create page with non-English text
     - Assert extraction completes without error
     - May extract fewer entities (acceptable)

5. Use `@pytest.mark.skipif` for tests that require spaCy model, with message "spaCy model not available".

6. Each test should be independent and use database fixtures where needed.
  </action>
  <verify>
```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_extraction_integration.py -v --tb=short 2>&1 | head -80
```
  </verify>
  <done>All integration tests pass, verifying NER-01 through NER-07 requirements are met by existing implementation.</done>
</task>

</tasks>

<verification>
Run all integration tests to verify extraction pipeline works end-to-end:

```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_extraction_integration.py -v
```

Expected: All tests pass, demonstrating requirements NER-01 through NER-07 are satisfied.
</verification>

<success_criteria>
- [ ] Fixture module provides realistic company page content
- [ ] Integration tests cover all 7 NER requirements
- [ ] Tests verify component wiring (EntityExtractor -> NLPPipeline -> Deduplicator)
- [ ] All tests pass with existing implementation
- [ ] Tests are documented with requirement traceability
</success_criteria>

<output>
After completion, create `.planning/phases/02-entity-extraction/02-01-SUMMARY.md`
</output>
