---
phase: 01-web-crawling
plan: 03
type: execute
wave: 2
depends_on:
  - 01-01
files_modified:
  - backend/tests/test_crawl_edge_cases.py
autonomous: true

must_haves:
  truths:
    - "Crawler handles malformed HTML without crashing"
    - "Crawler handles network timeouts gracefully"
    - "Crawler handles empty sitemaps without error"
    - "Crawler handles rate limit errors with backoff"
  artifacts:
    - path: "backend/tests/test_crawl_edge_cases.py"
      provides: "Edge case tests for crawler robustness"
      min_lines: 120
  key_links:
    - from: "CrawlWorker._fetch_page"
      to: "error handling"
      via: "try/except with CrawledPage.error"
      pattern: "error.*=|except"
    - from: "SitemapParser"
      to: "empty/missing sitemap"
      via: "graceful fallback"
      pattern: "urls.*\\[\\]|empty"
---

<objective>
Create edge case tests that verify the crawler handles error conditions gracefully.

Purpose: Validate robustness of the crawl implementation when facing malformed content, network issues, and edge conditions that occur in production.

Output: Edge case test file demonstrating crawler resilience.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-web-crawling/01-RESEARCH.md
@backend/app/crawlers/crawl_worker.py
@backend/app/crawlers/sitemap_parser.py
@backend/app/crawlers/browser_manager.py
@backend/tests/fixtures/crawl_fixtures.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create malformed content and network error tests</name>
  <files>backend/tests/test_crawl_edge_cases.py</files>
  <action>
Create edge case tests in `backend/tests/test_crawl_edge_cases.py`:

1. **Test class: TestMalformedContent**
   - `test_handles_malformed_html`:
     - Return HTML with unclosed tags, invalid nesting
     - Assert crawler extracts text without exception
     - Assert links are still discovered where possible

   - `test_handles_empty_html`:
     - Return empty string as HTML
     - Assert page is recorded with empty text
     - Assert no exception thrown

   - `test_handles_binary_content`:
     - Return binary garbage data
     - Assert page recorded with error or empty text
     - Assert crawler continues to next URL

   - `test_handles_non_utf8_encoding`:
     - Return content with ISO-8859-1 encoding
     - Assert content is decoded or gracefully handled
     - Assert no UnicodeDecodeError

2. **Test class: TestNetworkErrors**
   - `test_handles_connection_timeout`:
     - Mock fetcher to raise timeout exception
     - Assert page recorded with error message
     - Assert crawler continues to next URL

   - `test_handles_connection_refused`:
     - Mock fetcher to raise connection refused
     - Assert error recorded
     - Assert stopped_reason is not 'error' (continues crawling)

   - `test_handles_dns_resolution_failure`:
     - Mock DNS lookup failure
     - Assert graceful handling
     - Assert other URLs still crawled

   - `test_handles_ssl_certificate_error`:
     - Mock SSL verification failure
     - Assert recorded as error
     - Assert crawler continues

   - `test_handles_http_500_error`:
     - Return 500 status code
     - Assert page.is_success is False
     - Assert errors_count incremented

   - `test_handles_http_429_rate_limit`:
     - Return 429 with Retry-After header
     - Assert crawler respects backoff
     - Assert does not hammer server

Use fixtures from Plan 01 where applicable.
  </action>
  <verify>
```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_crawl_edge_cases.py::TestMalformedContent backend/tests/test_crawl_edge_cases.py::TestNetworkErrors -v --tb=short 2>&1 | head -50
```
  </verify>
  <done>Malformed content and network error tests pass, demonstrating crawler resilience.</done>
</task>

<task type="auto">
  <name>Task 2: Create sitemap and robots edge case tests</name>
  <files>backend/tests/test_crawl_edge_cases.py</files>
  <action>
Add sitemap and robots edge case tests to the existing file:

1. **Test class: TestSitemapEdgeCases**
   - `test_handles_missing_sitemap`:
     - Return 404 for sitemap.xml
     - Assert crawler falls back to link discovery
     - Assert homepage still crawled

   - `test_handles_empty_sitemap`:
     - Return valid XML with no URLs
     - Assert crawler proceeds with link discovery
     - Assert no exception

   - `test_handles_malformed_sitemap_xml`:
     - Return invalid XML (unclosed tags)
     - Assert graceful fallback
     - Assert link discovery still works

   - `test_handles_gzipped_sitemap`:
     - Return gzip-compressed sitemap
     - Assert URLs are extracted correctly

   - `test_handles_sitemap_index`:
     - Return sitemap index pointing to sub-sitemaps
     - Assert sub-sitemaps are fetched
     - Assert URLs from all sitemaps collected

2. **Test class: TestRobotsEdgeCases**
   - `test_handles_missing_robots_txt`:
     - Return 404 for robots.txt
     - Assert all URLs are allowed (permissive default)

   - `test_handles_malformed_robots_txt`:
     - Return invalid robots.txt content
     - Assert graceful handling
     - Assert default to allow

   - `test_handles_robots_with_crawl_delay`:
     - Return robots.txt with Crawl-delay: 5
     - Assert rate limiter respects delay
     - (Test timing if feasible, or verify config update)

Document each test with CRL requirement references.
  </action>
  <verify>
```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_crawl_edge_cases.py::TestSitemapEdgeCases backend/tests/test_crawl_edge_cases.py::TestRobotsEdgeCases -v --tb=short 2>&1 | head -40
```
  </verify>
  <done>Sitemap and robots edge case tests pass, demonstrating fallback behavior.</done>
</task>

<task type="auto">
  <name>Task 3: Add rate limiter stress tests</name>
  <files>backend/tests/test_crawl_edge_cases.py</files>
  <action>
Add rate limiting edge case tests to the existing file:

1. **Test class: TestRateLimiterEdgeCases**
   - `test_rate_limiter_enforces_1_per_second`:
     - Configure 1.0 requests_per_second
     - Attempt 5 rapid requests to same domain
     - Assert actual time elapsed >= 4 seconds (or verify blocking behavior)
     - Use time mocking if actual delay is impractical

   - `test_rate_limiter_allows_3_concurrent_max`:
     - Verify concurrent_limit configuration
     - Assert no more than 3 concurrent requests to same domain
     - (May need threading test or mock verification)

   - `test_rate_limiter_tracks_per_domain`:
     - Request to domain-a.com and domain-b.com
     - Assert each domain has independent bucket
     - Assert domain-a rate limit doesn't affect domain-b

   - `test_rate_limiter_timeout_on_acquire`:
     - Exhaust tokens, then acquire with short timeout
     - Assert returns False (not blocked forever)

   - `test_rate_limiter_resets_after_period`:
     - Exhaust tokens
     - Wait/mock time passage
     - Assert tokens replenished

2. Document each test with CRL-04 requirement reference.
  </action>
  <verify>
```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_crawl_edge_cases.py::TestRateLimiterEdgeCases -v --tb=short 2>&1
```
  </verify>
  <done>Rate limiter tests verify CRL-04 (1/sec, 3 concurrent max) requirement.</done>
</task>

</tasks>

<verification>
Run all edge case tests:

```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_crawl_edge_cases.py -v
```

Expected: All tests pass, demonstrating robust error handling for production scenarios.
</verification>

<success_criteria>
- [ ] Malformed content tests verify HTML parsing resilience
- [ ] Network error tests verify graceful degradation
- [ ] Sitemap edge cases verify fallback behavior
- [ ] Robots.txt edge cases verify permissive defaults
- [ ] Rate limiter tests verify CRL-04 compliance
- [ ] All tests pass with existing implementation
</success_criteria>

<output>
After completion, create `.planning/phases/01-web-crawling/01-03-SUMMARY.md`
</output>
