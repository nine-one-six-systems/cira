---
phase: 02-entity-extraction
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/tests/test_extraction_edge_cases.py
autonomous: true

must_haves:
  truths:
    - "Extraction handles empty and whitespace-only content gracefully"
    - "Extraction handles very long text without memory issues"
    - "Extraction handles non-English content without crashing"
    - "Invalid email domains are filtered out"
    - "Malformed phone numbers don't cause false positives"
    - "Performance meets 1000+ tokens/sec target"
  artifacts:
    - path: "backend/tests/test_extraction_edge_cases.py"
      provides: "Edge case and robustness tests for extraction"
      min_lines: 200
  key_links:
    - from: "NLPPipeline"
      to: "ExtractionConfig"
      via: "min_confidence filtering"
      pattern: "min_confidence"
    - from: "StructuredDataExtractor"
      to: "INVALID_EMAIL_DOMAINS"
      via: "email validation"
      pattern: "INVALID_EMAIL_DOMAINS"
---

<objective>
Create edge case tests that validate extraction robustness and error handling.

Purpose: Ensure the extraction pipeline handles unusual inputs, edge cases, and potential error conditions gracefully without crashing or producing invalid output.

Output: Edge case test file covering empty content, long text, non-English, malformed data, and performance validation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-entity-extraction/02-RESEARCH.md
@backend/app/extractors/nlp_pipeline.py
@backend/app/extractors/structured_extractor.py
@backend/tests/test_crawl_edge_cases.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create extraction edge case tests</name>
  <files>backend/tests/test_extraction_edge_cases.py</files>
  <action>
Create edge case tests at `backend/tests/test_extraction_edge_cases.py`:

1. **Test class: TestEmptyContentHandling**

   - `test_nlp_pipeline_handles_empty_string`:
     - Call pipeline.process_text('')
     - Assert returns empty list, no exception

   - `test_nlp_pipeline_handles_none`:
     - Call pipeline.process_text(None)
     - Assert returns empty list, no exception

   - `test_nlp_pipeline_handles_whitespace_only`:
     - Call pipeline.process_text('   \n\t   ')
     - Assert returns empty list, no exception

   - `test_structured_extractor_handles_empty_string`:
     - Call extractor.extract_all('')
     - Assert returns empty list, no exception

   - `test_entity_extractor_handles_empty_page` (app fixture):
     - Create page with empty extracted_text
     - Call extract_from_page()
     - Assert entities_extracted == 0
     - Assert no error

2. **Test class: TestLongTextHandling**

   - `test_nlp_pipeline_handles_long_text`:
     - Create text with 10,000+ words (repeat realistic sentence)
     - Call pipeline.process_text()
     - Assert completes without error
     - Assert returns entities (not empty)

   - `test_structured_extractor_handles_long_text`:
     - Create text with 50,000 characters
     - Embed emails and phones throughout
     - Call extract_all()
     - Assert completes without error
     - Assert finds embedded entities

   - `test_batch_processing_handles_many_texts`:
     - Create 100 texts of 500 words each
     - Call pipeline.process_batch()
     - Assert completes without error
     - Assert returns 100 result lists

3. **Test class: TestNonEnglishContent**

   - `test_nlp_pipeline_handles_non_english`:
     - Use text in Spanish, French, or German
     - Call pipeline.process_text()
     - Assert completes without error
     - (May extract fewer/no entities - acceptable)

   - `test_nlp_pipeline_handles_mixed_language`:
     - Use English text with embedded non-English phrases
     - Assert extracts English entities
     - Assert doesn't crash on non-English portions

   - `test_nlp_pipeline_handles_unicode`:
     - Use text with emojis, special characters, CJK characters
     - Assert completes without error

4. **Test class: TestEmailEdgeCases**

   - `test_rejects_example_domain_emails`:
     - Text with user@example.com, test@test.com
     - Assert these are NOT extracted (invalid domains)

   - `test_rejects_image_file_emails`:
     - Text with "image@company.png", "logo@brand.jpg"
     - Assert these are NOT extracted

   - `test_extracts_plus_addressed_emails`:
     - Text with "user+tag@company.com"
     - Assert extracted and normalized correctly

   - `test_extracts_obfuscated_emails`:
     - Text with "user [at] company [dot] com"
     - Assert extracted with lower confidence

   - `test_handles_malformed_email_patterns`:
     - Text with "@company.com", "user@", "user@.com"
     - Assert none extracted (invalid)

5. **Test class: TestPhoneEdgeCases**

   - `test_rejects_short_number_sequences`:
     - Text with "12345" or "555-12"
     - Assert not extracted as phones (too short)

   - `test_handles_various_separators`:
     - Text with "(555) 123-4567", "555.123.4567", "555 123 4567"
     - Assert all normalize to same +15551234567

   - `test_handles_international_prefix`:
     - Text with "+1 555 123 4567", "1-555-123-4567"
     - Assert extracted and normalized

   - `test_extracts_phone_with_extension`:
     - Text with "555-123-4567 ext. 123"
     - Assert phone extracted
     - Assert extension in extra_data

6. **Test class: TestConfidenceFiltering**

   - `test_low_confidence_entities_filtered`:
     - Configure pipeline with min_confidence=0.7
     - Process text with entities of varying quality
     - Assert only high-confidence entities returned

   - `test_single_character_entities_penalized`:
     - Process text where spaCy might extract single letters
     - Assert single-char entities have low confidence
     - Assert filtered by default threshold

   - `test_all_caps_entities_penalized`:
     - Process text with "JOHN SMITH" (all caps)
     - Assert confidence is slightly lower than "John Smith"

7. **Test class: TestPerformance**

   - `test_nlp_pipeline_meets_throughput_target`:
     - Create text of ~10,000 tokens
     - Time the extraction
     - Assert processes at 1000+ tokens/sec
     - Skip if spaCy not available

   - `test_batch_processing_faster_than_sequential`:
     - Create 50 texts of 200 words each
     - Time batch processing
     - Time sequential processing
     - Assert batch is faster (or at least equal)

8. **Test class: TestDeduplicatorEdgeCases**

   - `test_handles_empty_entity_list`:
     - Call deduplicate_entities([])
     - Assert returns empty list

   - `test_handles_entities_with_missing_fields`:
     - Entity dict missing 'context' or 'extra_data'
     - Assert doesn't crash
     - Assert uses defaults

   - `test_handles_very_similar_but_different_names`:
     - "John Smith" vs "John Smithson"
     - Assert NOT merged (different last name)

   - `test_handles_single_name_variations`:
     - "Madonna" vs "Madonna"
     - Assert merged (same single name)

9. Use `@pytest.mark.skipif` for tests requiring spaCy model.
10. Organize tests with clear class-based grouping by category.
  </action>
  <verify>
```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_extraction_edge_cases.py -v --tb=short 2>&1 | head -80
```
  </verify>
  <done>All edge case tests pass, demonstrating extraction pipeline is robust against unusual inputs and error conditions.</done>
</task>

</tasks>

<verification>
Run edge case tests to verify robustness:

```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_extraction_edge_cases.py -v
```

Expected: All tests pass, demonstrating extraction handles edge cases gracefully.
</verification>

<success_criteria>
- [ ] Empty/null content handled without exceptions
- [ ] Long text processed without memory issues
- [ ] Non-English content doesn't crash pipeline
- [ ] Invalid emails filtered (example.com, image extensions)
- [ ] Malformed phones not extracted as false positives
- [ ] Performance meets 1000+ tokens/sec target
- [ ] Deduplicator handles missing fields gracefully
</success_criteria>

<output>
After completion, create `.planning/phases/02-entity-extraction/02-03-SUMMARY.md`
</output>
