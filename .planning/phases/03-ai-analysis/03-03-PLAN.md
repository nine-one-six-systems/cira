---
phase: 03-ai-analysis
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/tests/test_analysis_edge_cases.py
autonomous: true

must_haves:
  truths:
    - "Analysis handles empty or missing content gracefully"
    - "Analysis handles very long content with truncation"
    - "API rate limiting recovered with exponential backoff"
    - "Partial failures preserve completed sections"
    - "Content preparation prioritizes high-value pages"
    - "Analysis handles companies with no entities"
  artifacts:
    - path: "backend/tests/test_analysis_edge_cases.py"
      provides: "Edge case and robustness tests for analysis"
      min_lines: 200
  key_links:
    - from: "AnalysisSynthesizer"
      to: "prepare_content_for_analysis()"
      via: "content truncation"
      pattern: "prepare_content|truncate"
    - from: "AnthropicService"
      to: "retry logic"
      via: "exponential backoff"
      pattern: "retry|backoff|RateLimitError"
---

<objective>
Create edge case tests that validate analysis robustness and error handling.

Purpose: Ensure the analysis pipeline handles unusual inputs, error conditions, and edge cases gracefully without crashing or producing invalid output.

Output: Edge case test file covering empty content, long text, API errors, partial failures, and recovery scenarios.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-ai-analysis/03-RESEARCH.md
@backend/app/services/anthropic_service.py
@backend/app/analysis/synthesis.py
@backend/tests/test_crawl_edge_cases.py
@backend/tests/test_extraction_edge_cases.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create analysis edge case tests</name>
  <files>backend/tests/test_analysis_edge_cases.py</files>
  <action>
Create edge case tests at `backend/tests/test_analysis_edge_cases.py`:

1. **Test class: TestEmptyContentHandling**

   - `test_analysis_handles_company_with_no_pages`:
     - Create company with 0 pages
     - Run analysis
     - Assert completes without exception
     - Assert analysis result indicates insufficient data

   - `test_analysis_handles_pages_with_empty_text`:
     - Create company with pages but all have empty extracted_text
     - Run analysis
     - Assert completes without exception
     - Assert appropriate fallback content generated

   - `test_analysis_handles_company_with_no_entities`:
     - Create company with pages but 0 entities
     - Run analysis
     - Assert completes without exception
     - Assert team_leadership section notes lack of data

   - `test_analysis_handles_only_external_pages`:
     - Create company where all pages are external (social profiles)
     - Run analysis
     - Assert completes without exception
     - Assert uses available external data

   - `test_analysis_handles_missing_page_types`:
     - Create company with only 'other' page types (no about, team, products)
     - Run analysis
     - Assert completes without exception
     - Assert sections acknowledge limited data

2. **Test class: TestLongContentHandling**

   - `test_truncates_content_to_max_length`:
     - Create pages with 100,000+ characters total
     - Run analysis
     - Assert content prepared for Claude is within limit (50000 chars)
     - Assert no API error for content too long

   - `test_prioritizes_about_and_team_pages`:
     - Create 50 pages of various types
     - Run analysis with truncation needed
     - Assert about and team page content preserved
     - Assert lower-priority pages truncated first

   - `test_per_page_type_truncation`:
     - Create very long team page (20000+ chars)
     - Run analysis
     - Assert per-type limit applied (10000 chars)
     - Assert content still usable for analysis

   - `test_handles_single_very_long_page`:
     - Create one page with 200,000 characters
     - Run analysis
     - Assert completes without memory error
     - Assert content truncated appropriately

3. **Test class: TestAPIErrorRecovery**

   - `test_recovers_from_rate_limit_error`:
     - Mock AnthropicService to raise RateLimitError on first 2 calls
     - Run analysis
     - Assert eventually succeeds after retries
     - Assert exponential backoff delays applied

   - `test_recovers_from_transient_api_error`:
     - Mock to raise APIError on first call, succeed on retry
     - Run analysis
     - Assert completes successfully

   - `test_fails_after_max_retries`:
     - Mock to always raise RateLimitError
     - Run analysis
     - Assert raises RateLimitError after max retries
     - Assert partial results preserved if any

   - `test_handles_api_timeout`:
     - Mock to raise TimeoutError
     - Run analysis
     - Assert timeout handled gracefully
     - Assert appropriate error message

   - `test_handles_invalid_api_response`:
     - Mock to return malformed response
     - Run analysis
     - Assert error handled
     - Assert no crash

4. **Test class: TestPartialFailureRecovery**

   - `test_preserves_completed_sections_on_failure`:
     - Mock to succeed for 3 sections, then fail
     - Run analysis
     - Assert first 3 sections saved
     - Assert failure logged with context

   - `test_can_resume_from_last_completed_section`:
     - Complete analysis to section 3, then simulate failure
     - Resume analysis
     - Assert only remaining sections processed
     - Assert no duplicate token charges

   - `test_section_failure_doesnt_corrupt_others`:
     - Mock to fail on 'market_position' section only
     - Run analysis
     - Assert other sections have valid content
     - Assert failed section marked appropriately

5. **Test class: TestContentPreparation**

   - `test_prepare_content_excludes_boilerplate`:
     - Create pages with common boilerplate (nav, footer, cookie notices)
     - Run content preparation
     - Assert boilerplate patterns filtered

   - `test_prepare_content_includes_entities`:
     - Create company with entities
     - Run content preparation
     - Assert entity context included for Claude

   - `test_prepare_content_formats_page_metadata`:
     - Create pages with titles and URLs
     - Run content preparation
     - Assert page titles and URLs formatted for Claude

   - `test_prepare_content_handles_unicode`:
     - Create pages with emojis and special characters
     - Run content preparation
     - Assert unicode preserved or safely encoded

6. **Test class: TestConcurrency**

   - `test_multiple_analyses_dont_interfere`:
     - Start analysis for 2 companies concurrently
     - Assert each gets correct results
     - Assert no token usage crossover

   - `test_handles_analysis_while_crawl_in_progress`:
     - Create company with status='crawling'
     - Attempt analysis
     - Assert appropriate error or queuing

7. **Test class: TestProgressReporting**

   - `test_progress_updates_on_each_section`:
     - Mock Redis
     - Run analysis
     - Assert 7 progress updates (one per section)
     - Assert progress shows correct section name

   - `test_progress_shows_failure_status`:
     - Mock section failure
     - Run analysis
     - Assert progress shows 'failed' status
     - Assert error details included

   - `test_stale_progress_detection`:
     - Set progress timestamp to 5 minutes ago
     - Assert progress considered stale
     - Assert warning logged

8. **Test class: TestTokenPricing**

   - `test_cost_calculation_with_zero_tokens`:
     - Calculate cost with 0 input, 0 output
     - Assert cost = 0.0
     - Assert no division error

   - `test_cost_calculation_precision`:
     - Calculate cost with small token counts
     - Assert 4+ decimal places preserved
     - Assert no floating point errors

   - `test_cost_uses_configurable_rates`:
     - Configure different input/output rates
     - Calculate cost
     - Assert new rates applied

9. Use `@pytest.fixture` for mock services.
10. Organize tests with clear class-based grouping matching test_extraction_edge_cases.py pattern.
  </action>
  <verify>
```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_analysis_edge_cases.py -v --tb=short 2>&1 | head -80
```
  </verify>
  <done>All edge case tests pass, demonstrating analysis pipeline is robust against unusual inputs and error conditions.</done>
</task>

</tasks>

<verification>
Run edge case tests to verify robustness:

```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_analysis_edge_cases.py -v
```

Expected: All tests pass, demonstrating analysis handles edge cases gracefully.
</verification>

<success_criteria>
- [ ] Empty/missing content handled without exceptions
- [ ] Long content truncated appropriately
- [ ] API rate limits handled with exponential backoff
- [ ] Partial failures preserve completed sections
- [ ] Content preparation prioritizes important pages
- [ ] Concurrent analyses don't interfere
- [ ] Progress reporting works correctly
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-analysis/03-03-SUMMARY.md`
</output>
