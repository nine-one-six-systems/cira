---
phase: 03-ai-analysis
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/tests/test_tokens_api_integration.py
autonomous: true

must_haves:
  truths:
    - "GET /companies/:id/tokens returns token usage breakdown"
    - "Response includes per-section token counts"
    - "Response includes total tokens and estimated cost"
    - "Response includes cost breakdown by API call type"
    - "Endpoint returns 404 for non-existent company"
  artifacts:
    - path: "backend/tests/test_tokens_api_integration.py"
      provides: "Integration tests for tokens API endpoint"
      min_lines: 120
  key_links:
    - from: "GET /companies/:id/tokens"
      to: "TokenUsage model"
      via: "SQLAlchemy query"
      pattern: "TokenUsage\\.query\\.filter"
    - from: "get_tokens()"
      to: "TokenUsageResponse schema"
      via: "response serialization"
      pattern: "TokenUsageResponse"
---

<objective>
Create API integration tests for the tokens endpoint that verify token usage retrieval and response format.

Purpose: Validate that the GET /companies/:id/tokens endpoint correctly returns token usage breakdown with per-section counts, totals, and cost estimation.

Output: API integration test file covering all tokens endpoint behaviors.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-ai-analysis/03-RESEARCH.md
@backend/app/api/routes/tokens.py
@backend/app/schemas/token.py
@backend/app/models/company.py
@backend/tests/conftest.py
@backend/tests/test_api_crawl_integration.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create tokens API integration tests</name>
  <files>backend/tests/test_tokens_api_integration.py</files>
  <action>
Create API integration tests at `backend/tests/test_tokens_api_integration.py`:

1. **Test class: TestGetTokenUsage**
   - Tests for GET /api/v1/companies/:id/tokens

   - `test_get_tokens_returns_empty_for_new_company`:
     - Create company with no analysis
     - GET /api/v1/companies/{id}/tokens
     - Assert 200 response
     - Assert data.totalTokens == 0
     - Assert data.estimatedCost == 0
     - Assert data.sections is empty array

   - `test_get_tokens_returns_usage_breakdown`:
     - Create company
     - Add TokenUsage records for 3 sections (executive_summary, company_overview, business_model)
     - GET /api/v1/companies/{id}/tokens
     - Assert 200 response
     - Assert data.sections has 3 items
     - Assert each section has: section, inputTokens, outputTokens

   - `test_get_tokens_calculates_totals`:
     - Create company with token records: section1 (500 in, 300 out), section2 (600 in, 400 out)
     - GET /api/v1/companies/{id}/tokens
     - Assert data.totalInputTokens == 1100
     - Assert data.totalOutputTokens == 700
     - Assert data.totalTokens == 1800

   - `test_get_tokens_includes_estimated_cost`:
     - Create company with known token usage
     - GET /api/v1/companies/{id}/tokens
     - Assert data.estimatedCost is number > 0
     - Assert cost calculated correctly based on pricing

   - `test_get_tokens_sections_ordered_by_timestamp`:
     - Create token records with different timestamps
     - GET /api/v1/companies/{id}/tokens
     - Assert sections returned in chronological order

2. **Test class: TestTokensResponseFormat**

   - `test_response_includes_all_required_fields`:
     - Create company with token usage
     - GET /api/v1/companies/{id}/tokens
     - Assert response has: totalInputTokens, totalOutputTokens, totalTokens, estimatedCost, sections

   - `test_section_response_includes_api_call_type`:
     - Create token records with api_call_type='analysis'
     - GET /api/v1/companies/{id}/tokens
     - Assert each section has apiCallType field

   - `test_section_response_includes_timestamp`:
     - Create token records
     - GET /api/v1/companies/{id}/tokens
     - Assert each section has timestamp in ISO format

   - `test_cost_formatted_as_decimal`:
     - GET /api/v1/companies/{id}/tokens
     - Assert estimatedCost is float/decimal (e.g., 0.0042)
     - Assert reasonable precision (4+ decimal places)

3. **Test class: TestTokensErrorHandling**

   - `test_get_tokens_company_not_found`:
     - GET /api/v1/companies/nonexistent-uuid/tokens
     - Assert 404 response
     - Assert error.code == 'NOT_FOUND'

   - `test_get_tokens_invalid_uuid_format`:
     - GET /api/v1/companies/not-a-uuid/tokens
     - Assert 404 or 400 response
     - Assert appropriate error message

4. **Test class: TestTokensAggregation**

   - `test_aggregates_multiple_calls_per_section`:
     - Create 2 token records for same section (e.g., retry scenario)
     - GET /api/v1/companies/{id}/tokens
     - Assert section appears once with combined totals
     OR
     - Assert both records appear chronologically

   - `test_handles_large_token_counts`:
     - Create token records with large values (100000+ tokens)
     - GET /api/v1/companies/{id}/tokens
     - Assert no overflow or truncation
     - Assert totals calculated correctly

   - `test_cost_aggregates_across_sections`:
     - Create token records for 5 sections
     - GET /api/v1/companies/{id}/tokens
     - Assert estimatedCost = sum of individual section costs

5. Use `app` fixture and `client` fixture from conftest.py for Flask test client.

6. Each test should create its own test data and be independent.

7. Create helper function `create_token_usage(db, company_id, section, input_tokens, output_tokens)` for reuse.
  </action>
  <verify>
```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_tokens_api_integration.py -v --tb=short 2>&1 | head -60
```
  </verify>
  <done>All API integration tests pass, verifying GET /companies/:id/tokens endpoint works correctly with proper token aggregation and cost calculation.</done>
</task>

</tasks>

<verification>
Run API integration tests to verify endpoint behavior:

```bash
cd /Users/stephenhollifield/Cira && python3 -m pytest backend/tests/test_tokens_api_integration.py -v
```

Expected: All tests pass, demonstrating tokens endpoint satisfies ANA-09 and ANA-10 requirements for token tracking and cost estimation exposure via API.
</verification>

<success_criteria>
- [ ] Tests cover GET /companies/:id/tokens endpoint
- [ ] Token usage breakdown returned with per-section counts
- [ ] Totals calculated correctly
- [ ] Cost estimation included in response
- [ ] Error cases handled properly (404)
- [ ] Response format matches TokenUsageResponse schema
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-analysis/03-02-SUMMARY.md`
</output>
